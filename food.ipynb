{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeB10ZMav-SW"
      },
      "source": [
        "#Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkSZ9-gPukrQ",
        "outputId": "78ad1d3f-aa8c-45af-b1c3-eb0f91dab567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vUbBvinu8zW"
      },
      "source": [
        "#Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4JsejDm3uxTS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2w52yYrvTu9"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hjVOjEZDWHm"
      },
      "source": [
        "#list image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OtrCB-QwDZ-9"
      },
      "outputs": [],
      "source": [
        "dataset_dir = f'/content/drive/MyDrive/Food dataset'\n",
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "test_dir = os.path.join(dataset_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmaWq9AODbi9",
        "outputId": "eef5dac3-aa36-4cd9-f7a0-db188c5b687d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tomat: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "wortel: \n",
            " \t82 train images,9 validation images, and 10 test images,total 101 images\n",
            "\n",
            "ubi: \n",
            " \t69 train images,10 validation images, and 10 test images,total 89 images\n",
            "\n",
            "sayap ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "pokcoy: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "salmon: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "telur: \n",
            " \t60 train images,10 validation images, and 10 test images,total 80 images\n",
            "\n",
            "tempe: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "selada: \n",
            " \t97 train images,9 validation images, and 10 test images,total 116 images\n",
            "\n",
            "tauge: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "terong: \n",
            " \t84 train images,10 validation images, and 10 test images,total 104 images\n",
            "\n",
            "tahu: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "semangka: \n",
            " \t84 train images,10 validation images, and 10 test images,total 104 images\n",
            "\n",
            "mangga: \n",
            " \t86 train images,10 validation images, and 10 test images,total 106 images\n",
            "\n",
            "paha ayam: \n",
            " \t70 train images,10 validation images, and 10 test images,total 90 images\n",
            "\n",
            "lobak: \n",
            " \t81 train images,9 validation images, and 10 test images,total 100 images\n",
            "\n",
            "mentimun: \n",
            " \t94 train images,10 validation images, and 10 test images,total 114 images\n",
            "\n",
            "nanas: \n",
            " \t99 train images,10 validation images, and 10 test images,total 119 images\n",
            "\n",
            "lemon: \n",
            " \t82 train images,10 validation images, and 10 test images,total 102 images\n",
            "\n",
            "labu siam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "pisang: \n",
            " \t75 train images,9 validation images, and 9 test images,total 93 images\n",
            "\n",
            "paprika: \n",
            " \t90 train images,9 validation images, and 10 test images,total 109 images\n",
            "\n",
            "kedelai: \n",
            " \t97 train images,10 validation images, and 10 test images,total 117 images\n",
            "\n",
            "jagung: \n",
            " \t87 train images,10 validation images, and 10 test images,total 107 images\n",
            "\n",
            "kacang polong: \n",
            " \t100 train images,10 validation images, and 10 test images,total 120 images\n",
            "\n",
            "labu: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "kiwi: \n",
            " \t88 train images,10 validation images, and 10 test images,total 108 images\n",
            "\n",
            "kentang: \n",
            " \t77 train images,10 validation images, and 10 test images,total 97 images\n",
            "\n",
            "jahe: \n",
            " \t68 train images,10 validation images, and 10 test images,total 88 images\n",
            "\n",
            "kembang kol: \n",
            " \t79 train images,10 validation images, and 10 test images,total 99 images\n",
            "\n",
            "jeruk: \n",
            " \t69 train images,9 validation images, and 10 test images,total 88 images\n",
            "\n",
            "kol: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "bayam: \n",
            " \t97 train images,10 validation images, and 10 test images,total 117 images\n",
            "\n",
            "brokoli: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "ceker ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "bawang putih: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "cabai: \n",
            " \t87 train images,9 validation images, and 10 test images,total 106 images\n",
            "\n",
            "bawang: \n",
            " \t94 train images,10 validation images, and 10 test images,total 114 images\n",
            "\n",
            "daun bawang: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "delima: \n",
            " \t79 train images,10 validation images, and 10 test images,total 99 images\n",
            "\n",
            "dada ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "anggur: \n",
            " \t100 train images,9 validation images, and 10 test images,total 119 images\n",
            "\n",
            "apel: \n",
            " \t68 train images,10 validation images, and 10 test images,total 88 images\n",
            "\n",
            "Sapi: \n",
            " \t45 train images,10 validation images, and 10 test images,total 65 images\n",
            "\n",
            "lengkuas: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "sawi putih: \n",
            " \t36 train images,15 validation images, and 10 test images,total 61 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def daftar_gambar():\n",
        "  classes_dirs = os.listdir(train_dir)\n",
        "  for label in classes_dirs:\n",
        "    train_classes = os.listdir(os.path.join(train_dir, label))\n",
        "    validation_classes = os.listdir(os.path.join(validation_dir, label))\n",
        "    test_classes = os.listdir(os.path.join(test_dir, label))\n",
        "    print(f\"{label}: \\n \\t{len(train_classes)} train images,{len(validation_classes)} validation images, and {len(test_classes)} test images,total {len(train_classes) + len(validation_classes) + len(test_classes)} images\")\n",
        "    print()\n",
        "daftar_gambar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU3NlcKCwlIZ"
      },
      "source": [
        "##Training Image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjoa0oUHvQAv",
        "outputId": "88f68b06-dcc4-4917-e6e7-a80729416675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3327 files belonging to 46 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Food dataset/train',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(32, 32),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK9Ev76o0mdJ"
      },
      "source": [
        "##Validation Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tocls4IowkNB",
        "outputId": "46efb4c0-ba60-4e46-9e19-489d136604bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 files belonging to 46 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Food dataset/validation',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(32, 32),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ_TcbD7r2Cw"
      },
      "source": [
        "#Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cUMiJrPvsBTU"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgFWYq7ssLkV"
      },
      "source": [
        "##Building Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LoaODWuZrHFg"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[32,32,3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b5-b7yo8mJHq"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5-potKmKsOr2"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0B29AmGWmZeV"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NPZ2NGthuTv5"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "demjWjcWuc3q"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=512,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_cD4jLBauZtk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=256,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2onuZO6YuBF3"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5)) #To avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "toAqflkCuwoS"
      },
      "outputs": [],
      "source": [
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=46,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYYdAFZDvt1P"
      },
      "source": [
        "#Compiling and Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yAcyiEfVvVzw"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0MROJsdlC5Z",
        "outputId": "b4c3c0e7-6216-496d-d205-aa2092103899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1180160   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46)                11822     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1388878 (5.30 MB)\n",
            "Trainable params: 1388878 (5.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "K3W4dNUrvxIw",
        "outputId": "2e661e6e-6acc-4111-9089-8f10418286ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-51aa8f2c2702>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
          ]
        }
      ],
      "source": [
        "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19E3mwj1phoW"
      },
      "source": [
        "##Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY6o3uxjpgl5"
      },
      "outputs": [],
      "source": [
        "#Training set Accuracy\n",
        "train_loss, train_acc = cnn.evaluate(training_set)\n",
        "print('Training accuracy:', train_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SaQgd7bpgwl"
      },
      "outputs": [],
      "source": [
        "#Validation set Accuracy\n",
        "val_loss, val_acc = cnn.evaluate(validation_set)\n",
        "print('Validation accuracy:', val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxp0xsjVBGec"
      },
      "source": [
        "##Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEUrBzCrxKt_"
      },
      "outputs": [],
      "source": [
        "cnn.save('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM-sILNMBwh1"
      },
      "outputs": [],
      "source": [
        "training_history.history #Return Dictionary of history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdF3Ig4ZBU9V"
      },
      "outputs": [],
      "source": [
        "#Recording History in json\n",
        "import json\n",
        "with open('training_hist.json','w') as f:\n",
        "  json.dump(training_history.history,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8PnAYbuCNhu"
      },
      "outputs": [],
      "source": [
        "print(training_history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwTEcIavCjZ8"
      },
      "source": [
        "##Calculating Accuracy of Model Achieved on Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Q2t6FXCUzR"
      },
      "outputs": [],
      "source": [
        "print(\"Validation set Accuracy: {} %\".format(training_history.history['val_accuracy'][-1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIMPXKFEZ5B"
      },
      "source": [
        "#Accuracy Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdg9Zjp2EfSa"
      },
      "source": [
        "##Training Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAvJjfBAFNJx"
      },
      "outputs": [],
      "source": [
        "#training_history.history['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfKdieuJCt3m"
      },
      "outputs": [],
      "source": [
        "epochs = [i for i in range(1,33)]\n",
        "plt.plot(epochs,training_history.history['accuracy'],color='red')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Traiining Accuracy')\n",
        "plt.title('Visualization of Training Accuracy Result')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOcpJL1FvJG"
      },
      "source": [
        "##Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXyC9WAJEs-B"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs,training_history.history['val_accuracy'],color='blue')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Visualization of Validation Accuracy Result')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mB3DkYFEuRg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJfYwGbmASaL"
      },
      "source": [
        "##Test set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGs_0S4AAUj_"
      },
      "outputs": [],
      "source": [
        "test_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_Vegetable_Recognition/test',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdMcF4vnAYuM"
      },
      "outputs": [],
      "source": [
        "test_loss,test_acc = cnn.evaluate(test_set)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmHXzT0PAiOn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}