{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeB10ZMav-SW"
      },
      "source": [
        "#Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkSZ9-gPukrQ",
        "outputId": "cc8614e6-4d3d-4812-9acc-d31bf1cfce11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vUbBvinu8zW"
      },
      "source": [
        "#Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JsejDm3uxTS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hjVOjEZDWHm"
      },
      "source": [
        "#list image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtrCB-QwDZ-9"
      },
      "outputs": [],
      "source": [
        "dataset_dir = f'/content/drive/MyDrive/Food dataset'\n",
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "validation_dir = os.path.join(dataset_dir, \"validation\")\n",
        "test_dir = os.path.join(dataset_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmaWq9AODbi9",
        "outputId": "8fb4e0cc-0645-4214-857e-e26772f95c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tomat: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "wortel: \n",
            " \t82 train images,9 validation images, and 10 test images,total 101 images\n",
            "\n",
            "ubi: \n",
            " \t69 train images,10 validation images, and 10 test images,total 89 images\n",
            "\n",
            "sayap ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "pokcoy: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "salmon: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "telur: \n",
            " \t60 train images,10 validation images, and 10 test images,total 80 images\n",
            "\n",
            "tempe: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "selada: \n",
            " \t97 train images,9 validation images, and 10 test images,total 116 images\n",
            "\n",
            "tauge: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "terong: \n",
            " \t84 train images,10 validation images, and 10 test images,total 104 images\n",
            "\n",
            "tahu: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "semangka: \n",
            " \t84 train images,10 validation images, and 10 test images,total 104 images\n",
            "\n",
            "mangga: \n",
            " \t86 train images,10 validation images, and 10 test images,total 106 images\n",
            "\n",
            "paha ayam: \n",
            " \t70 train images,10 validation images, and 10 test images,total 90 images\n",
            "\n",
            "lobak: \n",
            " \t81 train images,9 validation images, and 10 test images,total 100 images\n",
            "\n",
            "mentimun: \n",
            " \t94 train images,10 validation images, and 10 test images,total 114 images\n",
            "\n",
            "nanas: \n",
            " \t99 train images,10 validation images, and 10 test images,total 119 images\n",
            "\n",
            "lemon: \n",
            " \t82 train images,10 validation images, and 10 test images,total 102 images\n",
            "\n",
            "labu siam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "pisang: \n",
            " \t75 train images,9 validation images, and 9 test images,total 93 images\n",
            "\n",
            "paprika: \n",
            " \t90 train images,9 validation images, and 10 test images,total 109 images\n",
            "\n",
            "kedelai: \n",
            " \t97 train images,10 validation images, and 10 test images,total 117 images\n",
            "\n",
            "jagung: \n",
            " \t87 train images,10 validation images, and 10 test images,total 107 images\n",
            "\n",
            "kacang polong: \n",
            " \t100 train images,10 validation images, and 10 test images,total 120 images\n",
            "\n",
            "labu: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "kiwi: \n",
            " \t88 train images,10 validation images, and 10 test images,total 108 images\n",
            "\n",
            "kentang: \n",
            " \t77 train images,10 validation images, and 10 test images,total 97 images\n",
            "\n",
            "jahe: \n",
            " \t68 train images,10 validation images, and 10 test images,total 88 images\n",
            "\n",
            "kembang kol: \n",
            " \t79 train images,10 validation images, and 10 test images,total 99 images\n",
            "\n",
            "jeruk: \n",
            " \t69 train images,9 validation images, and 10 test images,total 88 images\n",
            "\n",
            "kol: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "bayam: \n",
            " \t97 train images,10 validation images, and 10 test images,total 117 images\n",
            "\n",
            "brokoli: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "ceker ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "bawang putih: \n",
            " \t92 train images,10 validation images, and 10 test images,total 112 images\n",
            "\n",
            "cabai: \n",
            " \t87 train images,9 validation images, and 10 test images,total 106 images\n",
            "\n",
            "bawang: \n",
            " \t94 train images,10 validation images, and 10 test images,total 114 images\n",
            "\n",
            "daun bawang: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "delima: \n",
            " \t79 train images,10 validation images, and 10 test images,total 99 images\n",
            "\n",
            "dada ayam: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "anggur: \n",
            " \t100 train images,9 validation images, and 10 test images,total 119 images\n",
            "\n",
            "apel: \n",
            " \t68 train images,10 validation images, and 10 test images,total 88 images\n",
            "\n",
            "Sapi: \n",
            " \t45 train images,10 validation images, and 10 test images,total 65 images\n",
            "\n",
            "lengkuas: \n",
            " \t50 train images,10 validation images, and 10 test images,total 70 images\n",
            "\n",
            "sawi putih: \n",
            " \t36 train images,15 validation images, and 10 test images,total 61 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def daftar_gambar():\n",
        "  classes_dirs = os.listdir(train_dir)\n",
        "  for label in classes_dirs:\n",
        "    train_classes = os.listdir(os.path.join(train_dir, label))\n",
        "    validation_classes = os.listdir(os.path.join(validation_dir, label))\n",
        "    test_classes = os.listdir(os.path.join(test_dir, label))\n",
        "    print(f\"{label}: \\n \\t{len(train_classes)} train images,{len(validation_classes)} validation images, and {len(test_classes)} test images,total {len(train_classes) + len(validation_classes) + len(test_classes)} images\")\n",
        "    print()\n",
        "daftar_gambar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2w52yYrvTu9"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU3NlcKCwlIZ"
      },
      "source": [
        "##Training Image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjoa0oUHvQAv",
        "outputId": "c93f7c6a-3630-4f80-e63d-915879afb9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3327 files belonging to 46 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Food dataset/train',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK9Ev76o0mdJ"
      },
      "source": [
        "##Validation Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tocls4IowkNB",
        "outputId": "a874c0a6-7b07-48b1-b31e-2af5f742140c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 450 files belonging to 46 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Food dataset/validation',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Model"
      ],
      "metadata": {
        "id": "2DhraXZMVZ-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Convolution Layer"
      ],
      "metadata": {
        "id": "DFXPzhDUViPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "2BD0RlYl46Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lapisan konvolusi\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "\n"
      ],
      "metadata": {
        "id": "xqJGTsOJ49Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=512,activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=256,activation='relu'))"
      ],
      "metadata": {
        "id": "O7CN_ZHusqit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5))"
      ],
      "metadata": {
        "id": "43PmV01JsstB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lapisan output\n",
        "cnn.add(tf.keras.layers.Dense(units=46, activation='softmax')) #use softmax cause multiclass cllasofication"
      ],
      "metadata": {
        "id": "dEL500-HXG2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compiling and Training Phase"
      ],
      "metadata": {
        "id": "Y_NZCfsrXgiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kompilasi model\n",
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tI26rnoz5DYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#callback\n",
        "class Akhir(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') > 0.91 and logs.get('val_accuracy') > 0.91):\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "mh_UFlk7aWnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan ringkasan model\n",
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW-XBerH5IE8",
        "outputId": "5a1bf916-f7f9-4e44-b555-abc41db2827c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10816)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               5538304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46)                11822     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5747022 (21.92 MB)\n",
            "Trainable params: 5747022 (21.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = Akhir()"
      ],
      "metadata": {
        "id": "u8QX20Stbhkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=32,callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB5ArSvNalHj",
        "outputId": "0fdeea35-8fa4-4ac8-caad-5f3e91b13a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "104/104 [==============================] - 606s 6s/step - loss: 5.1057 - accuracy: 0.0379 - val_loss: 3.6694 - val_accuracy: 0.0756\n",
            "Epoch 2/32\n",
            "104/104 [==============================] - 72s 654ms/step - loss: 3.6204 - accuracy: 0.0697 - val_loss: 3.5509 - val_accuracy: 0.1400\n",
            "Epoch 3/32\n",
            "104/104 [==============================] - 67s 617ms/step - loss: 3.4319 - accuracy: 0.1025 - val_loss: 3.2189 - val_accuracy: 0.1733\n",
            "Epoch 4/32\n",
            "104/104 [==============================] - 70s 630ms/step - loss: 3.2280 - accuracy: 0.1386 - val_loss: 2.8932 - val_accuracy: 0.2667\n",
            "Epoch 5/32\n",
            "104/104 [==============================] - 68s 621ms/step - loss: 2.9695 - accuracy: 0.1957 - val_loss: 2.6647 - val_accuracy: 0.3089\n",
            "Epoch 6/32\n",
            "104/104 [==============================] - 68s 619ms/step - loss: 2.6199 - accuracy: 0.2696 - val_loss: 2.3239 - val_accuracy: 0.4044\n",
            "Epoch 7/32\n",
            "104/104 [==============================] - 71s 650ms/step - loss: 2.2356 - accuracy: 0.3871 - val_loss: 2.2183 - val_accuracy: 0.5089\n",
            "Epoch 8/32\n",
            "104/104 [==============================] - 70s 620ms/step - loss: 1.7929 - accuracy: 0.4983 - val_loss: 2.1436 - val_accuracy: 0.5578\n",
            "Epoch 9/32\n",
            "104/104 [==============================] - 68s 621ms/step - loss: 1.4586 - accuracy: 0.5885 - val_loss: 2.0422 - val_accuracy: 0.5867\n",
            "Epoch 10/32\n",
            "104/104 [==============================] - 68s 616ms/step - loss: 1.1722 - accuracy: 0.6721 - val_loss: 1.9517 - val_accuracy: 0.6111\n",
            "Epoch 11/32\n",
            "104/104 [==============================] - 72s 653ms/step - loss: 0.9134 - accuracy: 0.7361 - val_loss: 2.6012 - val_accuracy: 0.6222\n",
            "Epoch 12/32\n",
            "104/104 [==============================] - 68s 618ms/step - loss: 0.9519 - accuracy: 0.7472 - val_loss: 2.5018 - val_accuracy: 0.6311\n",
            "Epoch 13/32\n",
            "104/104 [==============================] - 69s 617ms/step - loss: 0.7696 - accuracy: 0.7746 - val_loss: 2.2919 - val_accuracy: 0.6333\n",
            "Epoch 14/32\n",
            "104/104 [==============================] - 68s 624ms/step - loss: 0.6794 - accuracy: 0.8046 - val_loss: 2.5299 - val_accuracy: 0.6489\n",
            "Epoch 15/32\n",
            "104/104 [==============================] - 70s 634ms/step - loss: 0.6019 - accuracy: 0.8347 - val_loss: 2.4902 - val_accuracy: 0.6600\n",
            "Epoch 16/32\n",
            "104/104 [==============================] - 69s 630ms/step - loss: 0.8095 - accuracy: 0.7860 - val_loss: 2.3231 - val_accuracy: 0.6489\n",
            "Epoch 17/32\n",
            "104/104 [==============================] - 68s 618ms/step - loss: 0.5109 - accuracy: 0.8572 - val_loss: 2.4432 - val_accuracy: 0.6533\n",
            "Epoch 18/32\n",
            "104/104 [==============================] - 70s 624ms/step - loss: 0.4298 - accuracy: 0.8680 - val_loss: 2.8979 - val_accuracy: 0.6511\n",
            "Epoch 19/32\n",
            "104/104 [==============================] - 70s 640ms/step - loss: 0.3678 - accuracy: 0.8966 - val_loss: 3.0042 - val_accuracy: 0.6444\n",
            "Epoch 20/32\n",
            "104/104 [==============================] - 70s 625ms/step - loss: 0.3599 - accuracy: 0.9005 - val_loss: 3.3654 - val_accuracy: 0.6556\n",
            "Epoch 21/32\n",
            "104/104 [==============================] - 70s 644ms/step - loss: 0.3690 - accuracy: 0.8972 - val_loss: 2.9232 - val_accuracy: 0.6644\n",
            "Epoch 22/32\n",
            "104/104 [==============================] - 68s 613ms/step - loss: 0.3250 - accuracy: 0.9044 - val_loss: 3.1765 - val_accuracy: 0.6533\n",
            "Epoch 23/32\n",
            "104/104 [==============================] - 72s 661ms/step - loss: 0.2993 - accuracy: 0.9149 - val_loss: 2.7716 - val_accuracy: 0.6667\n",
            "Epoch 24/32\n",
            "104/104 [==============================] - 71s 645ms/step - loss: 0.2598 - accuracy: 0.9261 - val_loss: 2.9501 - val_accuracy: 0.6556\n",
            "Epoch 25/32\n",
            "104/104 [==============================] - 67s 614ms/step - loss: 0.2662 - accuracy: 0.9243 - val_loss: 2.9361 - val_accuracy: 0.6578\n",
            "Epoch 26/32\n",
            "104/104 [==============================] - 69s 622ms/step - loss: 0.2552 - accuracy: 0.9285 - val_loss: 3.2532 - val_accuracy: 0.6622\n",
            "Epoch 27/32\n",
            "104/104 [==============================] - 73s 666ms/step - loss: 0.2442 - accuracy: 0.9300 - val_loss: 3.1048 - val_accuracy: 0.6689\n",
            "Epoch 28/32\n",
            "104/104 [==============================] - 69s 617ms/step - loss: 0.1951 - accuracy: 0.9441 - val_loss: 3.2864 - val_accuracy: 0.6622\n",
            "Epoch 29/32\n",
            "104/104 [==============================] - 68s 625ms/step - loss: 0.1528 - accuracy: 0.9606 - val_loss: 3.1210 - val_accuracy: 0.6756\n",
            "Epoch 30/32\n",
            "104/104 [==============================] - 68s 613ms/step - loss: 0.1757 - accuracy: 0.9489 - val_loss: 3.5226 - val_accuracy: 0.6711\n",
            "Epoch 31/32\n",
            "104/104 [==============================] - 72s 656ms/step - loss: 0.1752 - accuracy: 0.9513 - val_loss: 4.0941 - val_accuracy: 0.6644\n",
            "Epoch 32/32\n",
            "104/104 [==============================] - 71s 647ms/step - loss: 0.1915 - accuracy: 0.9459 - val_loss: 3.5438 - val_accuracy: 0.6711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating Model"
      ],
      "metadata": {
        "id": "ej6bm1whYHj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY6o3uxjpgl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d78630b-b908-40a4-f224-64f305da5f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 69s 627ms/step - loss: 0.0538 - accuracy: 0.9850\n",
            "Training accuracy: 0.9849714636802673\n"
          ]
        }
      ],
      "source": [
        "#Training set Accuracy\n",
        "train_loss, train_acc = cnn.evaluate(training_set)\n",
        "print('Training accuracy:', train_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SaQgd7bpgwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cee162d-de44-4220-c6e9-9f79688087b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 9s 188ms/step - loss: 3.5438 - accuracy: 0.6711\n",
            "Validation accuracy: 0.6711111068725586\n"
          ]
        }
      ],
      "source": [
        "#Validation set Accuracy\n",
        "val_loss, val_acc = cnn.evaluate(validation_set)\n",
        "print('Validation accuracy:', val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxp0xsjVBGec"
      },
      "source": [
        "##Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEUrBzCrxKt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078ca9ff-b4ba-4ee1-d58e-dd3577038b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "cnn.save('trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM-sILNMBwh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c91e1d-eeac-4503-fd1a-0099c9150b8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [5.105728626251221,\n",
              "  3.6204140186309814,\n",
              "  3.4319136142730713,\n",
              "  3.228046178817749,\n",
              "  2.9695241451263428,\n",
              "  2.619938373565674,\n",
              "  2.2355549335479736,\n",
              "  1.7929034233093262,\n",
              "  1.4585685729980469,\n",
              "  1.172216773033142,\n",
              "  0.9134178161621094,\n",
              "  0.9518870711326599,\n",
              "  0.7695546746253967,\n",
              "  0.679431676864624,\n",
              "  0.6019150018692017,\n",
              "  0.8095355033874512,\n",
              "  0.5109373331069946,\n",
              "  0.42981797456741333,\n",
              "  0.3678155243396759,\n",
              "  0.3599150478839874,\n",
              "  0.3690222501754761,\n",
              "  0.3250303566455841,\n",
              "  0.2992856502532959,\n",
              "  0.25978386402130127,\n",
              "  0.2661871612071991,\n",
              "  0.2552342414855957,\n",
              "  0.24416238069534302,\n",
              "  0.1951075941324234,\n",
              "  0.15284375846385956,\n",
              "  0.17566752433776855,\n",
              "  0.17517206072807312,\n",
              "  0.19153673946857452],\n",
              " 'accuracy': [0.03787195682525635,\n",
              "  0.06973249465227127,\n",
              "  0.1024947389960289,\n",
              "  0.13856327533721924,\n",
              "  0.19567178189754486,\n",
              "  0.26961225271224976,\n",
              "  0.3871355652809143,\n",
              "  0.49834686517715454,\n",
              "  0.5885182023048401,\n",
              "  0.672076940536499,\n",
              "  0.73609858751297,\n",
              "  0.7472197413444519,\n",
              "  0.7745716571807861,\n",
              "  0.8046287894248962,\n",
              "  0.8346859216690063,\n",
              "  0.7859933972358704,\n",
              "  0.8572287559509277,\n",
              "  0.8680492639541626,\n",
              "  0.896603524684906,\n",
              "  0.9005109667778015,\n",
              "  0.8972046971321106,\n",
              "  0.904418408870697,\n",
              "  0.9149383902549744,\n",
              "  0.9260594844818115,\n",
              "  0.9242560863494873,\n",
              "  0.9284640550613403,\n",
              "  0.929966926574707,\n",
              "  0.9440937638282776,\n",
              "  0.960625171661377,\n",
              "  0.9489029049873352,\n",
              "  0.951307475566864,\n",
              "  0.9458972215652466],\n",
              " 'val_loss': [3.669419050216675,\n",
              "  3.5509047508239746,\n",
              "  3.2188758850097656,\n",
              "  2.8931849002838135,\n",
              "  2.664735794067383,\n",
              "  2.323895215988159,\n",
              "  2.218306541442871,\n",
              "  2.1435794830322266,\n",
              "  2.0422184467315674,\n",
              "  1.9516627788543701,\n",
              "  2.60115647315979,\n",
              "  2.501756429672241,\n",
              "  2.291862726211548,\n",
              "  2.5298595428466797,\n",
              "  2.490187168121338,\n",
              "  2.3231301307678223,\n",
              "  2.443244695663452,\n",
              "  2.897902011871338,\n",
              "  3.0041635036468506,\n",
              "  3.3654348850250244,\n",
              "  2.9232232570648193,\n",
              "  3.176462411880493,\n",
              "  2.771573305130005,\n",
              "  2.9500765800476074,\n",
              "  2.9361305236816406,\n",
              "  3.2531578540802,\n",
              "  3.1048192977905273,\n",
              "  3.286433219909668,\n",
              "  3.1209874153137207,\n",
              "  3.5226287841796875,\n",
              "  4.0940842628479,\n",
              "  3.543766736984253],\n",
              " 'val_accuracy': [0.07555555552244186,\n",
              "  0.14000000059604645,\n",
              "  0.1733333319425583,\n",
              "  0.2666666805744171,\n",
              "  0.30888888239860535,\n",
              "  0.40444445610046387,\n",
              "  0.5088889002799988,\n",
              "  0.5577777624130249,\n",
              "  0.5866666436195374,\n",
              "  0.6111111044883728,\n",
              "  0.6222222447395325,\n",
              "  0.6311110854148865,\n",
              "  0.6333333253860474,\n",
              "  0.648888885974884,\n",
              "  0.6600000262260437,\n",
              "  0.648888885974884,\n",
              "  0.653333306312561,\n",
              "  0.6511111259460449,\n",
              "  0.644444465637207,\n",
              "  0.6555555462837219,\n",
              "  0.6644444465637207,\n",
              "  0.653333306312561,\n",
              "  0.6666666865348816,\n",
              "  0.6555555462837219,\n",
              "  0.6577777862548828,\n",
              "  0.6622222065925598,\n",
              "  0.6688888669013977,\n",
              "  0.6622222065925598,\n",
              "  0.6755555272102356,\n",
              "  0.6711111068725586,\n",
              "  0.6644444465637207,\n",
              "  0.6711111068725586]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "training_history.history #Return Dictionary of history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdF3Ig4ZBU9V"
      },
      "outputs": [],
      "source": [
        "#Recording History in json\n",
        "import json\n",
        "with open('training_hist.json','w') as f:\n",
        "  json.dump(training_history.history,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8PnAYbuCNhu"
      },
      "outputs": [],
      "source": [
        "print(training_history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwTEcIavCjZ8"
      },
      "source": [
        "##Calculating Accuracy of Model Achieved on Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Q2t6FXCUzR"
      },
      "outputs": [],
      "source": [
        "print(\"Validation set Accuracy: {} %\".format(training_history.history['val_accuracy'][-1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIMPXKFEZ5B"
      },
      "source": [
        "#Accuracy Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdg9Zjp2EfSa"
      },
      "source": [
        "##Training Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAvJjfBAFNJx"
      },
      "outputs": [],
      "source": [
        "#training_history.history['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfKdieuJCt3m"
      },
      "outputs": [],
      "source": [
        "epochs = [i for i in range(1,33)]\n",
        "plt.plot(epochs,training_history.history['accuracy'],color='red')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Traiining Accuracy')\n",
        "plt.title('Visualization of Training Accuracy Result')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOcpJL1FvJG"
      },
      "source": [
        "##Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXyC9WAJEs-B"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs,training_history.history['val_accuracy'],color='blue')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Visualization of Validation Accuracy Result')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mB3DkYFEuRg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJfYwGbmASaL"
      },
      "source": [
        "##Test set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGs_0S4AAUj_"
      },
      "outputs": [],
      "source": [
        "test_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_Vegetable_Recognition/test',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdMcF4vnAYuM"
      },
      "outputs": [],
      "source": [
        "test_loss,test_acc = cnn.evaluate(test_set)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmHXzT0PAiOn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}